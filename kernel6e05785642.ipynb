{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Part of this code is due to the MatConvNet team and is used to load the parameters of the pretrained VGG19 model in the notebook ###\n\nimport os\nimport sys\nimport scipy.io\nimport scipy.misc\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\nimport pprint\n%matplotlib inline\n\n\nclass CONFIG:\n    IMAGE_WIDTH = 400\n    IMAGE_HEIGHT = 300\n    COLOR_CHANNELS = 3\n    NOISE_RATIO = 0.6\n    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3)) \n    VGG_MODEL = 'pretrained-model/imagenet-vgg-verydeep-19.mat' # Pick the VGG 19-layer model by from the paper \"Very Deep Convolutional Networks for Large-Scale Image Recognition\".\n    STYLE_IMAGE = 'images/stone_style.jpg' # Style image to use.\n    CONTENT_IMAGE = 'images/content300.jpg' # Content image to use.\n    OUTPUT_DIR = 'output/'\n    \ndef load_vgg_model(path):\n   \n    vgg = scipy.io.loadmat(path)\n\n    vgg_layers = vgg['layers']\n    \n    def _weights(layer, expected_layer_name):\n        \n        wb = vgg_layers[0][layer][0][0][2]\n        W = wb[0][0]\n        b = wb[0][1]\n        layer_name = vgg_layers[0][layer][0][0][0][0]\n        assert layer_name == expected_layer_name\n        return W, b\n\n        return W, b\n\n    def _relu(conv2d_layer):\n        return tf.nn.relu(conv2d_layer)\n\n    def _conv2d(prev_layer, layer, layer_name):\n        W, b = _weights(layer, layer_name)\n        W = tf.constant(W)\n        b = tf.constant(np.reshape(b, (b.size)))\n        return tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n\n    def _conv2d_relu(prev_layer, layer, layer_name):\n        return _relu(_conv2d(prev_layer, layer, layer_name))\n\n    def _avgpool(prev_layer):\n        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n    # Constructs the graph model.\n    graph = {}\n    graph['input']   = tf.Variable(np.zeros((1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)), dtype = 'float32')\n    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n    \n    return graph\n\ndef generate_noise_image(content_image, noise_ratio = CONFIG.NOISE_RATIO):\n    # Generate a random noise_image\n    noise_image = np.random.uniform(-20, 20, (1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)).astype('float32')\n    \n    # Set the input_image to be a weighted average of the content_image and a noise_image\n    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n    \n    return input_image\n\n\ndef reshape_and_normalize_image(image):\n    # Reshape image to mach expected input of VGG16\n    image = np.reshape(image, ((1,) + image.shape))\n    \n    # Substract the mean to match the expected input of VGG16\n    image = image - CONFIG.MEANS\n    \n    return image\n\n\ndef save_image(path, image):\n    \n    # Un-normalize the image so that it looks good\n    image = image + CONFIG.MEANS\n    \n    # Clip and Save the image\n    image = np.clip(image[0], 0, 255).astype('uint8')\n    scipy.misc.imsave(path, image)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport scipy.io\nimport scipy.misc\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom PIL import Image\n\nimport numpy as np\nimport tensorflow as tf\nimport pprint\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pp = pprint.PrettyPrinter(indent=4)\nmodel = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\npp.pprint(model)\ncontent_image = scipy.misc.imread(\"images/louvre.jpg\")\nimshow(content_image);\ndef compute_content_cost(a_C, a_G):\n    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n    a_C_unrolled = tf.transpose(a_C)\n    a_G_unrolled = tf.transpose(a_G)\n    J_content = (1/ (4* n_H * n_W * n_C)) * tf.reduce_sum(tf.pow((a_G_unrolled - a_C_unrolled), 2))\n    return J_content\nstyle_image = scipy.misc.imread(\"images/monet_800600.jpg\")\nimshow(style_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gram_matrix(A):\n    GA = tf.matmul(A, tf.transpose(A))\n    return GA\ndef compute_layer_style_cost(a_S, a_G):\n    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n    a_S = tf.transpose(tf.reshape(a_S, [n_H*n_W, n_C]))\n    a_G = tf.transpose(tf.reshape(a_G, [n_H*n_W, n_C]))\n    GS = gram_matrix(a_S)\n    GG = gram_matrix(a_G)\n    J_style_layer = (1./(4 * n_C**2 * (n_H*n_W)**2)) * tf.reduce_sum(tf.pow((GS - GG), 2))\n    return J_style_layer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STYLE_LAYERS = [\n    ('conv1_1', 0.2),\n    ('conv2_1', 0.2),\n    ('conv3_1', 0.2),\n    ('conv4_1', 0.2),\n    ('conv5_1', 0.2)]\ndef compute_style_cost(model, STYLE_LAYERS):\n    J_style = 0\n    for layer_name, coeff in STYLE_LAYERS:\n        out = model[layer_name]\n        a_S = sess.run(out)\n        a_G = out\n        J_style_layer = compute_layer_style_cost(a_S, a_G)\n        J_style += coeff * J_style_layer\n    return J_style\ndef total_cost(J_content, J_style, alpha = 10, beta = 40):\n    J = alpha * J_content + beta * J_style\n    return J\ntf.reset_default_graph()\nsess = tf.InteractiveSession()\ncontent_image = scipy.misc.imread(\"images/louvre_small.jpg\")\ncontent_image = reshape_and_normalize_image(content_image)\nstyle_image = scipy.misc.imread(\"images/monet.jpg\")\nstyle_image = reshape_and_normalize_image(style_image)\ngenerated_image = generate_noise_image(content_image)\nimshow(generated_image[0]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\nsess.run(model['input'].assign(content_image))\nout = model['conv4_2']\na_C = sess.run(out)\na_G = out\nJ_content = compute_content_cost(a_C, a_G)\nsess.run(model['input'].assign(style_image))\nJ_style = compute_style_cost(model, STYLE_LAYERS)\nJ = total_cost(J_content, J_style, alpha = 10, beta = 40)\noptimizer = tf.train.AdamOptimizer(2.0)\ntrain_step = optimizer.minimize(J)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_nn(sess, input_image, num_iterations = 200):\n    sess.run(tf.global_variables_initializer())\n    sess.run(model['input'].assign(input_image))\n    for i in range(num_iterations):\n        sess.run(train_step)\n        generated_image = sess.run(model['input'])\n        if i%20 == 0:\n            Jt, Jc, Js = sess.run([J, J_content, J_style])\n            print(\"Iteration \" + str(i) + \" :\")\n            print(\"content cost = \" + str(Jc))\n            print(\"style cost = \" + str(Js))\n            save_image(\"output/\" + str(i) + \".png\", generated_image)\n    save_image('output/generated_image.jpg', generated_image)\n    return generated_image\nmodel_nn(sess, generated_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}